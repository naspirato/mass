# ============================================================================
# ПРИМЕР КОНФИГУРАЦИИ АНАЛИТИКИ МЕТРИК YDB
# ============================================================================
# Этот файл демонстрирует все доступные опции конфигурации
# Скопируйте этот файл и адаптируйте под свои нужды
# ============================================================================

job:
  # Уникальное имя задачи (используется для имен таблиц, файлов отчетов)
  name: "tpcc_performance_analysis"
  
  # Описание задачи (для документации)
  description: "Анализ метрик TPC-C производительности"

# ----------------------------------------------------------------------------
# ИСТОЧНИК ДАННЫХ
# ----------------------------------------------------------------------------
data_source:
  # Автоматическая агрегация данных по времени (опционально)
  # Формат: число + единица (1h, 15min, 1D, 30S)
  # Если не указано, используются исходные данные без агрегации
  # aggregate_by: "1h"  # Раскомментируйте, если нужна агрегация
  
  # Настройки подключения к YDB и SQL-запрос
  ydb:
    # SQL-запрос для получения данных из YDB
    # Должен возвращать:
    # - поле с временной меткой (timestamp_field)
    # - поля для контекста (context_fields)
    # - поля для метрик (metric_fields)
    query: |
      SELECT 
        timestamp,
        cluster,
        warehouses,
        duration_seconds,
        git_branch,
        run_type,
        tpmC as metric_value,
        'tpmC' as metric_name
      FROM `perfomance/tpcc`
      WHERE timestamp >= CurrentUtcDate() - 30 * Interval("P1D")
      
      UNION ALL
      
      SELECT 
        timestamp,
        cluster,
        warehouses,
        duration_seconds,
        git_branch,
        run_type,
        newOrderLatency90 as metric_value,
        'newOrderLatency90' as metric_name
      FROM `perfomance/tpcc`
      WHERE timestamp >= CurrentUtcDate() - 30 * Interval("P1D")
        AND newOrderLatency90 IS NOT NULL

# ----------------------------------------------------------------------------
# СТРУКТУРА ДАННЫХ
# ----------------------------------------------------------------------------
# Поля, по которым группируются данные (создают уникальные контексты)
# Например: ["cluster", "warehouses", "git_branch"] создаст группы:
# - (cluster=A, warehouses=10, git_branch=main)
# - (cluster=B, warehouses=20, git_branch=feature)
# и т.д.
context_fields: ["cluster", "warehouses", "git_branch", "run_type", "duration_seconds"]

# Поля, которые содержат информацию о метрике
# Первое поле - название метрики (например, "tpmC", "latency_ms")
# Второе поле - значение метрики (число)
metric_fields: ["metric_name", "metric_value"]

# Поле с временной меткой (должно быть типа Timestamp или DateTime)
timestamp_field: "timestamp"

# ----------------------------------------------------------------------------
# НАПРАВЛЕНИЕ МЕТРИК
# ----------------------------------------------------------------------------
# Определяет, как интерпретировать изменения метрик:
# - "negative" = больше значение = хуже (latency, error_count, error_rate)
#   → рост = degradation, падение = improvement
# - "positive" = больше значение = лучше (throughput, success_rate, tpmC)
#   → рост = improvement, падение = degradation
metric_direction:
  # Направление по умолчанию для всех метрик
  default: "positive"  # По умолчанию: больше = лучше (для tpmC)
  
  # Направление для конкретных метрик (переопределяет default)
  tpmC: "positive"                    # Throughput - позитивная метрика
  newOrderLatency90: "negative"       # Latency - негативная метрика (больше = хуже)
  # duration_ms: "negative"
  # error_rate: "negative"

# ----------------------------------------------------------------------------
# НАСТРОЙКИ АНАЛИТИКИ
# ----------------------------------------------------------------------------
analytics:
  # Метод расчета baseline (нормального значения)
  # Варианты:
  #   - "rolling_mean" - скользящее среднее (рекомендуется)
  #   - "rolling_median" - скользящая медиана (устойчивее к выбросам)
  #   - "zscore" - статистический метод на основе Z-score
  #   - "prophet" - Facebook Prophet (для сложных трендов)
  #   - "adtk-levelshift" - ADTK для обнаружения сдвигов уровня
  baseline_method: "rolling_mean"
  
  # Размер окна для расчета baseline (в количестве точек данных)
  # Например, при агрегации по 1 часу и window_size=24:
  # baseline будет рассчитываться на основе последних 24 часов
  window_size: 7
  
  # Чувствительность порогов (множитель стандартного отклонения)
  # 2.0 = пороги на расстоянии 2 сигм от baseline
  # Больше значение = менее чувствительно (меньше ложных срабатываний)
  # Меньше значение = более чувствительно (больше событий)
  sensitivity: 2.0
  
  # Минимальное абсолютное изменение для регистрации события
  # Например, 5 означает: событие регистрируется только если значение
  # изменилось минимум на 5 единиц
  min_absolute_change: 5
  
  # Минимальное относительное изменение (от 0.0 до 1.0)
  # Например, 0.05 = 5% изменение
  # Событие регистрируется только если изменение >= min_relative_change
  min_relative_change: 0.05
  
  # Количество точек подряд для подтверждения события (гистерезис)
  # Предотвращает ложные срабатывания от единичных выбросов
  # Например, 2 означает: нужно 2 точки подряд вне порогов
  hysteresis_points: 2
  
  # Адаптивные пороги (автоматически подстраиваются под волатильность)
  # true = пороги адаптируются к недавней волатильности
  # false = пороги фиксированные на основе всей истории
  adaptive_threshold: true
  
  # Минимальное количество точек данных для анализа группы
  # Группы с меньшим количеством точек будут пропущены
  min_data_points: 3
  
  # Параметры для конкретных метрик (опционально)
  # Позволяет настроить разные параметры для разных метрик
  metric_specific_params:
    tpmC:
      min_absolute_change: 400        # Для tpmC: изменение 400+ считается значимым
      min_relative_change: 0.002     # 0.2% относительное изменение
    newOrderLatency90:
      min_absolute_change: 5          # Для newOrderLatency90: изменение 5+ мс считается значимым
      min_relative_change: 0.05      # 5% относительное изменение

# ----------------------------------------------------------------------------
# ОТСЛЕЖИВАНИЕ ИЗМЕНЕНИЙ КОНТЕКСТОВ (опционально)
# ----------------------------------------------------------------------------
# Эта секция позволяет отслеживать появление и исчезновение контекстов
# Полезно для метрик, где появление нового контекста = событие
# Например, для ошибок:
# - Новый контекст (новая ошибка) = негативное событие
# - Исчезнувший контекст (ошибка пропала) = позитивное событие
#
# Раскомментируйте и настройте, если нужно отслеживать появление/исчезновение:
# context_tracking:
#   track_new_contexts: true
#   track_disappeared_contexts: true
#   
#   context_change_rules:
#     new_context_metrics:
#       error_count:
#         event_type: "degradation_start"
#         severity: "high"
#         baseline_before: 0.0
#     
#     disappeared_context_metrics:
#       error_count:
#         event_type: "improvement_start"
#         severity: "medium"
#         baseline_after: 0.0
#         min_absence_points: 3
#         absence_type: "consecutive"
#         min_historical_points: 2

# ----------------------------------------------------------------------------
# ОБНАРУЖЕНИЕ СОБЫТИЙ
# ----------------------------------------------------------------------------
events:
  # Типы событий для обнаружения
  detect:
    - degradation_start   # Начало деградации (значение стало хуже)
    - improvement_start    # Начало улучшения (значение стало лучше)
    # - threshold_shift     # Сдвиг baseline (изменение нормального уровня)
  
  # Имя таблицы в YDB для сохранения событий (опционально)
  # output_table: "analytics/events"
  
  # Минимальная длительность события в минутах
  # События короче этого времени будут отфильтрованы
  # (предотвращает ложные срабатывания от кратковременных всплесков)
  min_event_duration_minutes: 15

# ----------------------------------------------------------------------------
# ПОРОГИ И BASELINE
# ----------------------------------------------------------------------------
thresholds:
  # Имя таблицы в YDB для сохранения порогов и baseline (опционально)
  # output_table: "analytics/thresholds"
  
  # Сохранять историю изменений порогов
  # true = сохранять все версии порогов
  # false = обновлять только последние значения
  keep_history: true

# ----------------------------------------------------------------------------
# ВЫВОД РЕЗУЛЬТАТОВ
# ----------------------------------------------------------------------------
output:
  # Сохранять результаты в YDB
  write_to_ydb: true
  
  # Выводить логи в консоль
  log_to_console: true
  
  # Режим "сухого прогона" (не сохранять в YDB, только в локальные файлы)
  # Полезно для тестирования и отладки
  dry_run: false

# ----------------------------------------------------------------------------
# НАСТРОЙКИ ВЫПОЛНЕНИЯ
# ----------------------------------------------------------------------------
runtime:
  # Часовой пояс для обработки временных меток
  timezone: "UTC"
  
  # Максимальное время выполнения задачи в минутах
  # Задача будет прервана, если превысит это время
  max_runtime_minutes: 15
